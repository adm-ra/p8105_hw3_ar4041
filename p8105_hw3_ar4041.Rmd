---
title: "Homework 3"
output: github_document
Author: Adam R
editor_options: 
  chunk_output_type: console
---
```{r setup, include= FALSE}
library(tidyverse)
library(patchwork)
library(p8105.datasets)
library("hexbin")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in order by user. There are user/order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. There's also some information about the user's past behaviors -- whether or not the customer has ordered this in the past and days since last order. 

how many aisles, and which are they from?

```{r aisles}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are 134 aisles, and the most ordered are fresh vegetables, fresh fruit, and packaged vegetables and fruits.

let's make a plot

```{r plot1}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

making a table

```{r table1}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

apples v ice cream table 
```{r apples_ice}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2

```{r tidying, warning = FALSE}
accel_df = 
  read_csv(
    "./accel_data.csv",
    ) %>% 
  janitor::clean_names() %>%
    mutate(day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>% 
  pivot_longer(
    starts_with("activity"),
    names_to = 'activity_num',
    names_prefix = "activity_",
    values_to = 'active_val'
  ) %>% 
  mutate(w_end = case_when(
     day == "Monday" ~ "weekday",
     day == "Tuesday" ~ "weekday",
     day == "Wednesday" ~ "weekday",
     day == "Thursday" ~ "weekday",
     day == "Friday" ~ "weekday",
     day == "Saturday" ~ "weekend",
     day == "Sunday" ~ "weekend",
     TRUE ~ ""
  )) %>% 
  select(-day_id) %>% 
  arrange(week, day)
```

This dataset contains `r nrow(accel_df)` observations of activity data over `r max(pull(accel_df, week))` weeks. This dataset contains the variables `r names(accel_df)`. 

```{r accel_table, warning = FALSE}
accel_df = 
  read_csv(
    "./accel_data.csv",
    ) %>% 
  janitor::clean_names() %>% 
  mutate(day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>% 
  pivot_longer(
    starts_with("activity"),
    names_to = 'activity_num',
    names_prefix = "activity_",
    values_to = 'active_val'
  ) %>% 
  mutate(w_end = case_when(
     day == "Monday" ~ "weekday",
     day == "Tuesday" ~ "weekday",
     day == "Wednesday" ~ "weekday",
     day == "Thursday" ~ "weekday",
     day == "Friday" ~ "weekday",
     day == "Saturday" ~ "weekend",
     day == "Sunday" ~ "weekend",
     TRUE ~ ""
  )) %>% 
  select(-day_id) %>% 
  group_by(week, day) %>% 
  summarize(
    daily_total_act = sum(active_val)
  ) %>% 
  knitr::kable()
```

While major trends are not immediately apparent in the table, it does appear that there is less activity on weekends. 

```{r plots, warning = FALSE}
accel_df = 
  read_csv(
    "./accel_data.csv",
    ) %>% 
  janitor::clean_names() %>% 
  mutate(day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>% 
  pivot_longer(
    starts_with("activity"),
    names_to = 'active_num',
    names_prefix = "activity_",
    values_to = 'active_val'
  ) %>% 
  mutate(w_end = case_when(
     day == "Monday" ~ "weekday",
     day == "Tuesday" ~ "weekday",
     day == "Wednesday" ~ "weekday",
     day == "Thursday" ~ "weekday",
     day == "Friday" ~ "weekday",
     day == "Saturday" ~ "weekend",
     day == "Sunday" ~ "weekend",
     TRUE ~ ""
  )) %>% 
  group_by(week, day) %>% 
  summarise(active_mean = mean(active_val)) %>% 
  ggplot(aes(x = week , y = active_mean, color = day)) + 
  geom_smooth() +
   labs(
    title = "Activity Plot",
    x = "Week",
    y = "Mean Activity"
  )

accel_df
```

Based on this graph, it appears that weekend activity starts around the same level as weekday activity, but decreases significantly by week 3. 

## Problem 3

```{r noaa}
data("ny_noaa")
```

This dataset contains the variables `r names(ny_noaa)`. The dataset has `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns. The variable "prcp" refers to precipitation in tenths of millimeters; "snow" refers to snowfall in millimeters; and snwd refers to snow depth in millimeters. 

```{r noaa_clean, warning = FALSE}
ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
  mutate(
    tmax = as.numeric(tmax)/100,
    tmin = as.numeric(tmin)/100
  ) %>% 
  group_by(snow) %>% 
  count(snow) %>% 
  arrange(desc(n))
```

For snowfall, the most commonly seen values by far are 0 and NA. This is because there are many days without snowfall in NY, and because there is a lot of missing data in this dataset. 

```{r temps, warning = FALSE}
ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
   filter(month == 1 | month == 7) %>% 
  mutate(
    tmax = as.numeric(tmax)/10,
    tmin = as.numeric(tmin)/10
  ) %>% 
  group_by(id, year, month) %>% 
  summarize(tmax_mean = tmax) %>% 
  drop_na(tmax_mean) %>% 
  ggplot(aes(x = year, y = tmax_mean)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) + 
  facet_grid(. ~ month,
             labeller = label_both) +
  theme(legend.position = "none") +
  labs(
    title = "Mean Max Temperatures by Year",
    x = "Year",
    y = "Mean Max"
  )
```

While there are occasional outlier years, max January temperatures appear to be increasing as the years progress. July temperatures appear to have remained constant. 

```{r tmax_min, warning = FALSE}
tmax_tmin_p = 
  ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
  mutate(
    tmax = as.numeric(tmax)/10,
    tmin = as.numeric(tmin)/10
  ) %>% 
  drop_na(tmin) %>% 
  drop_na(tmax) %>% 
  ggplot(aes(x = tmax, y = tmin, size = tmax)) +
  geom_hex() +
  labs(
   title = "Max and Min Temperatures",
    x = "Max Temperature",
    y = "Min Temperature"
  )

snowfall_p = 
  ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
  drop_na(snow) %>% 
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = year, fill = )) + 
  geom_histogram() +
  labs(
    title = "Snowfall by Year",
    x = "Year",
    y = "# of Days 0-100 mm of snow"
  )

tmax_tmin_p + snowfall_p
```


